#!/bin/bash
# Script de lancement optimisÃ© et complet pour RLT (SFT + RL)

set -e  # ArrÃªt sur erreur

echo "ðŸš€ RLT Training Launcher - SFT + RL Pipeline"
echo "=================================================================="

# VÃ©rification du rÃ©pertoire
if [ ! -f "train.py" ]; then
    echo "âŒ Erreur: train.py non trouvÃ©. Lancez depuis le rÃ©pertoire RLT."
    exit 1
fi

# VÃ©rification GPU
if ! command -v nvidia-smi &> /dev/null; then
    echo "âŒ Erreur: nvidia-smi non trouvÃ©. GPU NVIDIA requis."
    exit 1
fi

# Affichage des informations GPU
echo "ðŸ“Š Informations GPU :"
nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader,nounits
echo ""

# La configuration est maintenant gÃ©rÃ©e via les fichiers YAML
echo "âœ… Configuration chargÃ©e depuis les fichiers cfgs/."

# On s'assure que WANDB est en mode offline
export WANDB_MODE=offline
export PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True,max_split_size_mb:64"

# --- Ã‰TAPE 1: SUPERVISED FINE-TUNING (SFT) ---
echo ""
echo "--- Ã‰TAPE 1: Lancement du prÃ©-entraÃ®nement SFT ---"
echo "Objectif: CrÃ©er le modÃ¨le de base dans 'results/pre_rl_model'"
echo ""

# VÃ©rification si le modÃ¨le SFT existe dÃ©jÃ 
if [ -d "results/pre_rl_model" ] && [ -f "results/pre_rl_model/pytorch_model.bin" ]; then
    echo "âœ… Le modÃ¨le prÃ©-entraÃ®nÃ© (SFT) existe dÃ©jÃ  dans 'results/pre_rl_model'."
    echo "   Saut de l'Ã©tape SFT."
else
    echo "ðŸ”§ Le modÃ¨le SFT n'existe pas. Lancement de l'entraÃ®nement..."
    # On utilise la config SFT existante et on ajoute les optimisations ultimes
    python3 train.py \
        +run_cfg=teacher_sft \
        +do_sft=true \
        use_peft=true \
        +model_args.load_in_8bit=true \
        gradient_checkpointing=true \
        bf16=false \
        max_steps=200 \
        max_seq_length=2048 \
        packing=false \
        add_text_completions=true \
        wandb_project=rl4lm_sft_85gb \
        +trainer_args.optim=paged_adamw_8bit

    if [ ! -f "SFT_model_pre_RL/adapter_model.safetensors" ]; then
        echo "âŒ ERREUR: L'entraÃ®nement SFT a Ã©chouÃ©. Le fichier modÃ¨le n'a pas Ã©tÃ© crÃ©Ã©."
        exit 1
    fi
    
    echo "âœ… Ã‰tape 1 (SFT) terminÃ©e avec succÃ¨s !"
fi

# --- Ã‰TAPE 2: REINFORCEMENT LEARNING (RL) ---
echo ""
echo "--- Ã‰TAPE 2: Lancement de l'entraÃ®nement par renforcement (RL) ---"

# Lancement de l'entraÃ®nement RL
echo "ðŸš€ Lancement de l'entraÃ®nement RLT..."
echo "   (W&B est configurÃ© en mode offline pour Ã©viter les erreurs d'API Key)"
echo "   Logs GPU en temps rÃ©el: tail -f gpu_monitoring.log"
echo ""

python3 train.py \
    "${BASE_PARAMS[@]}" \
    "${CONFIG_PARAMS[@]}" \
    2>&1 | tee rl_training_$(date +%Y%m%d_%H%M%S).log

echo ""
echo "âœ… EntraÃ®nement RL terminÃ© !"

# Monitoring en arriÃ¨re-plan
echo "ðŸ“Š DÃ©marrage du monitoring GPU..."
nvidia-smi --query-gpu=timestamp,memory.used,memory.total,utilization.gpu --format=csv -l 10 > gpu_monitoring.log &
MONITOR_PID=$!

# Fonction de nettoyage
cleanup() {
    echo ""
    echo "ðŸ›‘ ArrÃªt du training..."
    kill $MONITOR_PID 2>/dev/null || true
    echo "ðŸ“Š Log GPU sauvegardÃ© : gpu_monitoring.log"
}
trap cleanup EXIT

echo "ðŸ“Š Consultez les logs: training_*.log et gpu_monitoring.log" 