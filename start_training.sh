#!/bin/bash
# Script de lancement optimisÃ© et complet pour RLT (SFT + RL)

set -e  # ArrÃªt sur erreur

echo "ðŸš€ RLT Training Launcher - SFT + RL Pipeline"
echo "=================================================================="

# VÃ©rification du rÃ©pertoire
if [ ! -f "train.py" ]; then
    echo "âŒ Erreur: train.py non trouvÃ©. Lancez depuis le rÃ©pertoire RLT."
    exit 1
fi

# VÃ©rification GPU
if ! command -v nvidia-smi &> /dev/null; then
    echo "âŒ Erreur: nvidia-smi non trouvÃ©. GPU NVIDIA requis."
    exit 1
fi

# Affichage des informations GPU
echo "ðŸ“Š Informations GPU :"
nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader,nounits
echo ""

# VÃ©rification VRAM (minimum 80GB)
VRAM_TOTAL=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits | head -1)
if [ "$VRAM_TOTAL" -lt 80000 ]; then
    echo "âŒ Erreur: VRAM insuffisante ($VRAM_TOTAL MB). Minimum requis: 80GB"
    exit 1
fi

echo "âœ… VRAM suffisante: ${VRAM_TOTAL} MB"

# Choix de configuration
echo ""
echo "ðŸŽ¯ Choisissez votre niveau de performance :"
echo "1) Conservative (~50GB VRAM) - RECOMMANDÃ‰"
echo "2) Aggressive (~65GB VRAM)"
read -p "Votre choix (1 ou 2): " config_choice

# ParamÃ¨tres de base pour 85GB
# Note: Le '+' indique Ã  Hydra d'ajouter la clÃ© si elle n'existe pas.
BASE_PARAMS=(
    "+run_cfg=teacher_rlt"
    "model_name_or_path=results/pre_rl_model"
    "max_steps=200"
    "+model_init_kwargs.load_in_8bit=true"
    "+model_init_kwargs.device_map=auto"
    "+model_args.load_in_8bit=true"
    "use_vllm=true"
    "use_vllm_server=false"
    "offload_untrained_models=true"
    "sync_ref_model=false"
    "wandb_project=rl4lm_teacher_85gb_8bit"
    "gradient_checkpointing=true"
    "fp16=false"
    "bf16=false"
    "+trainer_args.optim=paged_adamw_8bit"
)

# ParamÃ¨tres spÃ©cifiques Ã  la configuration choisie
if [[ "$config_choice" == "2" ]]; then
    echo "âš¡ Configuration Aggressive sÃ©lectionnÃ©e"
    CONFIG_PARAMS=(
        "train_batch_size=32"
        "per_device_train_batch_size=2"
        "generation_aggregation_steps=16"
        "num_generations=24"
        "max_prompt_length=8192"
        "max_completion_length=8192"
        "vllm_gpu_memory_utilization=0.55"
        "output_dir=results/rlt_teacher_85gb_aggressive"
    )
else
    echo "ðŸ›¡ï¸  Configuration Conservative sÃ©lectionnÃ©e (dÃ©faut)"
    CONFIG_PARAMS=(
        "train_batch_size=32"
        "per_device_train_batch_size=2"
        "gradient_accumulation_steps=16"
        "max_steps=1000"
        "max_prompt_length=2048"
        "max_completion_length=2048"
        "wandb_project=rl4lm_sft_85gb"
        "output_dir=results/pre_rl_model"
    )
fi

echo "âœ… Configuration chargÃ©e."

# On s'assure que WANDB est en mode offline
export WANDB_MODE=offline
export PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True,max_split_size_mb:64"

# --- Ã‰TAPE 1: SUPERVISED FINE-TUNING (SFT) ---
echo ""
echo "--- Ã‰TAPE 1: Lancement du prÃ©-entraÃ®nement SFT ---"
echo "Objectif: CrÃ©er le modÃ¨le de base dans 'results/pre_rl_model'"
echo ""

# VÃ©rification si le modÃ¨le SFT existe dÃ©jÃ 
if [ -d "results/pre_rl_model" ] && [ -f "results/pre_rl_model/pytorch_model.bin" ]; then
    echo "âœ… Le modÃ¨le prÃ©-entraÃ®nÃ© (SFT) existe dÃ©jÃ  dans 'results/pre_rl_model'."
    echo "   Saut de l'Ã©tape SFT."
else
    echo "ðŸ”§ Le modÃ¨le SFT n'existe pas. Lancement de l'entraÃ®nement..."
    # On utilise la config SFT existante et on ajoute les optimisations ultimes
    python3 train.py \
        +run_cfg=teacher_sft \
        +do_sft=true \
        +model_args.load_in_8bit=true \
        gradient_checkpointing=true \
        bf16=false \
        per_device_train_batch_size=1 \
        gradient_accumulation_steps=16 \
        max_steps=1000 \
        max_seq_length=2048 \
        packing=false \
        add_text_completions=true \
        wandb_project=rl4lm_sft_85gb \
        output_dir="results/pre_rl_model" \
        +trainer_args.optim=paged_adamw_8bit

    if [ ! -f "results/pre_rl_model/pytorch_model.bin" ]; then
        echo "âŒ ERREUR: L'entraÃ®nement SFT a Ã©chouÃ©. Le fichier modÃ¨le n'a pas Ã©tÃ© crÃ©Ã©."
        exit 1
    fi
    
    echo "âœ… Ã‰tape 1 (SFT) terminÃ©e avec succÃ¨s !"
fi

# --- Ã‰TAPE 2: REINFORCEMENT LEARNING (RL) ---
echo ""
echo "--- Ã‰TAPE 2: Lancement de l'entraÃ®nement par renforcement (RL) ---"

# Lancement de l'entraÃ®nement RL
echo "ðŸš€ Lancement de l'entraÃ®nement RLT..."
echo "   (W&B est configurÃ© en mode offline pour Ã©viter les erreurs d'API Key)"
echo "   Logs GPU en temps rÃ©el: tail -f gpu_monitoring.log"
echo ""

python3 train.py \
    "${BASE_PARAMS[@]}" \
    "${CONFIG_PARAMS[@]}" \
    2>&1 | tee rl_training_$(date +%Y%m%d_%H%M%S).log

echo ""
echo "âœ… EntraÃ®nement RL terminÃ© !"

# Monitoring en arriÃ¨re-plan
echo "ðŸ“Š DÃ©marrage du monitoring GPU..."
nvidia-smi --query-gpu=timestamp,memory.used,memory.total,utilization.gpu --format=csv -l 10 > gpu_monitoring.log &
MONITOR_PID=$!

# Fonction de nettoyage
cleanup() {
    echo ""
    echo "ðŸ›‘ ArrÃªt du training..."
    kill $MONITOR_PID 2>/dev/null || true
    echo "ðŸ“Š Log GPU sauvegardÃ© : gpu_monitoring.log"
}
trap cleanup EXIT

echo "ðŸ“Š Consultez les logs: training_*.log et gpu_monitoring.log" 