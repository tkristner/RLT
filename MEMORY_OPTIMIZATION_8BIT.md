# ðŸš€ Optimisation MÃ©moire avec Quantification 8-bit

## ðŸ“Š **Ã‰conomies Spectaculaires**

La quantification 8-bit (`load_in_8bit=True`) rÃ©duit drastiquement l'usage VRAM :

```
AVANT (bfloat16):      APRÃˆS (8-bit):        Ã‰CONOMIE:
â”œâ”€â”€ Teacher: 14GB  â†’   â”œâ”€â”€ Teacher: 7GB   â†’   -7GB (-50%)
â”œâ”€â”€ Student: 14GB  â†’   â”œâ”€â”€ Student: 7GB   â†’   -7GB (-50%)  
â”œâ”€â”€ Reference: 14GB â†’   â”œâ”€â”€ Reference: 7GB â†’   -7GB (-50%)
â””â”€â”€ TOTAL: 42GB        â””â”€â”€ TOTAL: 21GB       -21GB (-50%)

MÃ‰MOIRE TOTALE:
â€¢ Sans 8-bit: ~68GB (marge 17GB)
â€¢ Avec 8-bit: ~50GB (marge 35GB) 
â€¢ GAIN: +18GB de marge supplÃ©mentaire!
```

## ðŸŽ¯ **Configurations Disponibles**

### 1. **Configuration Conservative (RecommandÃ©e)**
```bash
python train.py --config-path=cfgs/run_cfg --config-name=teacher_rlt_mono_85gb
```
- **Usage**: ~50GB (35GB libre)
- **ParamÃ¨tres**: batch_size=64, generations=16, context=6144  
- **Pour**: Premier entraÃ®nement, tests de stabilitÃ©

### 2. **Configuration Aggressive (Performance Max)**
```bash
python train.py --config-path=cfgs/run_cfg --config-name=teacher_rlt_mono_85gb_aggressive
```
- **Usage**: ~65GB (20GB libre)
- **ParamÃ¨tres**: batch_size=128, generations=32, context=8192
- **Pour**: Maximiser performance quand le systÃ¨me est stable

## âš¡ **Avantages de la Quantification 8-bit**

### **âœ… BÃ©nÃ©fices:**
- **50% rÃ©duction** de l'usage mÃ©moire des modÃ¨les
- **Inference plus rapide** (moins de transferts mÃ©moire)
- **CompatibilitÃ©** excellente avec bitsandbytes
- **Perte de prÃ©cision** < 1-2% (nÃ©gligeable)

### **âš ï¸ ConsidÃ©rations:**
- **Premier chargement** lÃ©gÃ¨rement plus lent (quantification)
- **CPU usage** temporaire durant la quantification
- **Compatible** uniquement avec GPU rÃ©cents (Ampere+)

## ðŸ”§ **Configuration Technique**

La quantification 8-bit est activÃ©e via :

```yaml
model_args:
  load_in_8bit: true      # Quantification 8-bit
  device_map: auto        # Mapping automatique des couches
  torch_dtype: bfloat16   # Dtype pour les calculs
```

## ðŸ“ˆ **Recommandations d'Usage**

1. **Commencer** avec la configuration conservative
2. **Monitorer** l'usage mÃ©moire avec `nvidia-smi`
3. **Passer** Ã  aggressive si stable et besoin de performance
4. **Ajuster** batch_size selon les rÃ©sultats d'entraÃ®nement

## ðŸŽ® **Commandes de Monitoring**

```bash
# Surveiller VRAM en temps rÃ©el
watch -n 1 nvidia-smi

# Logger usage mÃ©moire
nvidia-smi --query-gpu=memory.used,memory.total --format=csv -l 5 > memory_log.csv
``` 